<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Xiang An's Community Contribution - Open Source Projects">
    <title>Community Contribution - Xiang An</title>
    <link rel="icon" href="assets/img/profile_pic.jpg" type="image/jpg">
    <style>
        :root {
            --primary-color: #2563eb;
            --primary-hover: #1d4ed8;
            --text-dark: #1f2937;
            --text-gray: #4b5563;
            --text-light: #6b7280;
            --bg-page: #ffffff;
            --bg-card: #ffffff;
            --border-color: #e5e7eb;
        }

        body {
            font-family: "Times New Roman", Georgia, serif;
            color: var(--text-dark);
            background-color: var(--bg-page);
            margin: 0;
            padding: 80px 20px 40px 20px;
            line-height: 1.6;
            font-weight: 400;
        }

        /* Site Header - 保留导航栏样式 */
        .site-header {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 52px;
            background-color: rgba(255, 255, 255, 0.95);
            backdrop-filter: saturate(180%) blur(20px);
            -webkit-backdrop-filter: saturate(180%) blur(20px);
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0 32px;
            box-sizing: border-box;
            z-index: 1000;
            border-bottom: 1px solid var(--border-color);
        }

        .header-logo {
            font-size: 1.1rem;
            font-weight: 600;
            color: var(--text-dark);
            text-decoration: none;
        }

        .header-logo:hover {
            color: var(--primary-color);
        }

        .site-nav {
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .nav-link {
            font-size: 0.85rem;
            font-weight: 400;
            color: var(--text-dark);
            text-decoration: none;
            padding: 8px 14px;
            border-radius: 4px;
        }

        .nav-link:hover {
            background-color: #f3f4f6;
            color: var(--text-dark);
        }

        .nav-link:active {
            background-color: #e5e7eb;
        }

        /* Mobile hamburger menu */
        .nav-toggle {
            display: none;
            background: none;
            border: none;
            cursor: pointer;
            padding: 8px;
            z-index: 1002;
        }

        .nav-toggle span {
            display: block;
            width: 22px;
            height: 2px;
            background-color: #1f2937;
            margin: 5px 0;
            transition: transform 0.3s ease, opacity 0.3s ease;
        }

        .nav-toggle.active span:nth-child(1) {
            transform: rotate(45deg) translate(5px, 5px);
        }

        .nav-toggle.active span:nth-child(2) {
            opacity: 0;
        }

        .nav-toggle.active span:nth-child(3) {
            transform: rotate(-45deg) translate(5px, -5px);
        }

        /* Mobile navigation overlay */
        .nav-overlay {
            display: none;
            position: fixed;
            top: 52px;
            left: 0;
            width: 100%;
            height: calc(100vh - 52px);
            background-color: rgba(255, 255, 255, 0.98);
            z-index: 999;
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        .nav-overlay.active {
            display: block;
            opacity: 1;
        }

        .mobile-nav {
            display: none;
            flex-direction: column;
            padding: 20px 24px;
        }

        .mobile-nav .nav-link {
            font-size: 1rem;
            padding: 14px 0;
            border-bottom: 1px solid var(--border-color);
            border-radius: 0;
        }

        .mobile-nav .nav-link:last-child {
            border-bottom: none;
        }

        .mobile-nav .nav-link:hover {
            background-color: transparent;
            color: var(--primary-color);
        }

        #layout-content {
            margin: 0 auto;
            max-width: 850px;
            background-color: var(--bg-card);
            padding: 40px 50px;
        }

        .page-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 32px;
            padding-bottom: 16px;
            border-bottom: 2px solid var(--text-dark);
        }

        .page-header h1 {
            font-size: 1.8rem;
            margin: 0;
            color: var(--text-dark);
            font-weight: 700;
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            padding: 6px 14px;
            font-size: 0.9em;
            font-weight: 500;
            color: var(--primary-color);
            text-decoration: none;
            border: 1px solid var(--primary-color);
        }

        .back-link:hover {
            background: var(--primary-color);
            color: #fff;
        }

        .back-link::before {
            content: "←";
            margin-right: 6px;
        }

        .intro-text {
            color: var(--text-gray);
            margin-bottom: 32px;
            font-size: 1rem;
            line-height: 1.7;
        }

        .intro-text b {
            color: var(--text-dark);
            font-weight: 600;
        }

        .project-card {
            background: var(--bg-card);
            border: 1px solid var(--border-color);
            padding: 24px;
            margin-bottom: 20px;
        }

        .project-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 14px;
            gap: 16px;
        }

        .project-title {
            font-size: 1.2rem;
            font-weight: 700;
            color: var(--text-dark);
            margin: 0;
            line-height: 1.4;
        }

        .project-stars {
            display: inline-flex;
            align-items: center;
            padding: 4px 12px;
            font-size: 0.85rem;
            font-weight: 600;
            color: #fff;
            background: var(--primary-color);
            white-space: nowrap;
            flex-shrink: 0;
        }

        .project-summary {
            color: var(--text-gray);
            font-size: 1rem;
            margin-bottom: 14px;
            line-height: 1.6;
        }

        .project-details {
            color: var(--text-dark);
            font-size: 0.95rem;
            line-height: 1.7;
            margin-bottom: 18px;
        }

        .project-details h4 {
            color: var(--text-dark);
            font-size: 1rem;
            font-weight: 600;
            margin: 16px 0 8px 0;
        }

        .project-details ul {
            margin: 8px 0;
            padding-left: 20px;
        }

        .project-details li {
            margin-bottom: 6px;
            color: var(--text-gray);
        }

        .project-details a {
            color: var(--primary-color);
            text-decoration: none;
        }

        .project-details a:hover {
            text-decoration: underline;
        }

        .project-links {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
        }

        .project-link {
            display: inline-flex;
            align-items: center;
            padding: 6px 14px;
            font-size: 0.9rem;
            font-weight: 500;
            text-decoration: none;
        }

        .project-link.primary {
            color: #fff;
            background: var(--primary-color);
        }

        .project-link.primary:hover {
            background: var(--primary-hover);
        }

        .project-link.secondary {
            color: var(--text-dark);
            background-color: transparent;
            border: 1px solid var(--border-color);
        }

        .project-link.secondary:hover {
            background-color: #f3f4f6;
        }

        /* Mobile */
        @media (max-width: 768px) {
            body {
                padding: 68px 0 0 0;
                background-color: #fff;
            }

            .site-header {
                padding: 0 16px;
                height: 48px;
            }

            .header-logo {
                font-size: 1rem;
            }

            .nav-toggle {
                display: block;
            }

            .site-nav {
                display: none;
            }

            .nav-overlay.active .mobile-nav {
                display: flex;
            }

            #layout-content {
                padding: 24px 16px;
                width: auto;
                margin: 0;
            }

            .page-header {
                flex-direction: column;
                align-items: flex-start;
                gap: 12px;
            }

            .page-header h1 {
                font-size: 1.5rem;
            }

            .project-header {
                flex-direction: column;
            }

            .project-card {
                padding: 20px;
            }

            .project-title {
                font-size: 1.1rem;
            }
        }

        /* Print */
        @media print {
            .site-header {
                display: none;
            }

            @page {
                margin: 1cm 1cm;
                size: auto;
            }

            body {
                background-color: #fff;
                padding: 0;
                margin: 0;
            }

            #layout-content {
                margin: 0;
                width: 100%;
                max-width: none !important;
                padding: 0;
                border: none;
            }

            .back-link {
                display: none;
            }

            .project-card {
                break-inside: avoid;
                page-break-inside: avoid;
            }
        }
    </style>
</head>

<body>

    <!-- Site Header (Meta-style fixed navigation) -->
    <header class="site-header">
        <a href="index.html" class="header-logo">Xiang An</a>
        <nav class="site-nav">
            <a href="index.html#publications" class="nav-link">Selected Publications</a>
            <a href="publications.html" class="nav-link">All Publications</a>
            <a href="community.html" class="nav-link">Community Contribution</a>
            <a href="index.html#awards" class="nav-link">Awards & Competitions</a>
        </nav>
        <button class="nav-toggle" aria-label="Toggle navigation">
            <span></span>
            <span></span>
            <span></span>
        </button>
    </header>

    <!-- Mobile Navigation Overlay -->
    <div class="nav-overlay">
        <nav class="mobile-nav">
            <a href="index.html#publications" class="nav-link">Publications</a>
            <a href="publications.html" class="nav-link">All Pubs</a>
            <a href="community.html" class="nav-link">Community</a>
            <a href="index.html#awards" class="nav-link">Awards</a>
        </nav>
    </div>

    <script>
        // Mobile navigation toggle
        document.addEventListener('DOMContentLoaded', function() {
            const navToggle = document.querySelector('.nav-toggle');
            const navOverlay = document.querySelector('.nav-overlay');
            const mobileNavLinks = document.querySelectorAll('.mobile-nav .nav-link');

            navToggle.addEventListener('click', function() {
                navToggle.classList.toggle('active');
                navOverlay.classList.toggle('active');
                document.body.style.overflow = navOverlay.classList.contains('active') ? 'hidden' : '';
            });

            // Close menu when clicking a link
            mobileNavLinks.forEach(function(link) {
                link.addEventListener('click', function() {
                    navToggle.classList.remove('active');
                    navOverlay.classList.remove('active');
                    document.body.style.overflow = '';
                });
            });

            // Close menu when clicking overlay background
            navOverlay.addEventListener('click', function(e) {
                if (e.target === navOverlay) {
                    navToggle.classList.remove('active');
                    navOverlay.classList.remove('active');
                    document.body.style.overflow = '';
                }
            });
        });
    </script>

    <div id="layout-content">
        <div class="page-header">
            <h1>Community Contribution</h1>
            <a href="index.html" class="back-link">Back to Home</a>
        </div>

        <p class="intro-text">
            I actively contribute to open-source projects in face recognition, representation learning, and multimodal large models. I am the <b>#2 contributor</b> to the <b>InsightFace</b> ecosystem (~27k⭐), and co-maintain several influential vision and multimodal repositories.
        </p>

        <!-- InsightFace -->
        <div class="project-card">
            <div class="project-header">
                <h2 class="project-title">InsightFace · 2D & 3D Face Analysis Toolkit</h2>
                <span class="project-stars">⭐ 27k+ Stars</span>
            </div>
            <p class="project-summary">
                Major contributor (#2 by contributions) to the core InsightFace ecosystem for large-scale face recognition and analysis.
            </p>
            <div class="project-details">
                <h4>Project Overview</h4>
                <p>InsightFace is an open-source 2D & 3D deep face analysis library with more than 27k stars on GitHub. It provides state-of-the-art face recognition, detection, alignment, and analysis capabilities.</p>
                
                <h4>My Contributions</h4>
                <ul>
                    <li>Author of <a href="https://github.com/deepinsight/insightface/tree/master/recognition/_datasets_" target="_blank"><b>Glint360K</b></a>, the largest open-source face recognition training dataset</li>
                    <li>Organizer of <a href="https://github.com/deepinsight/insightface/tree/master/challenges/iccv21-mfr" target="_blank"><b>ICCV 2021 Workshop</b></a> on masked face recognition challenge</li>
                    <li>Author of <a href="https://github.com/deepinsight/insightface/tree/master/recognition/partial_fc" target="_blank"><b>Partial FC</b></a>, enabling training 10 million identities on a single machine</li>
                    <li>Implemented <a href="https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch" target="_blank"><b>arcface_torch</b></a>, an efficient distributed training framework</li>
                </ul>
                
                <h4>Key Features</h4>
                <ul>
                    <li>State-of-the-art face recognition models (ArcFace, CosFace, etc.)</li>
                    <li>Support for large-scale training with millions of identities</li>
                </ul>
            </div>
            <div class="project-links">
                <a href="https://github.com/deepinsight/insightface" class="project-link primary" target="_blank">View on GitHub</a>
                <a href="https://arxiv.org/abs/2203.15565" class="project-link secondary" target="_blank">Partial FC Paper</a>
            </div>
        </div>

        <!-- LLaVA-OneVision-1.5 -->
        <div class="project-card">
            <div class="project-header">
                <h2 class="project-title">LLaVA-OneVision-1.5 · Multimodal Training Framework</h2>
                <span class="project-stars">⭐ 600+ Stars</span>
            </div>
            <p class="project-summary">
                Fully open framework for democratized multimodal training, advancing large multimodal models (LMMs).
            </p>
            <div class="project-details">
                <h4>Project Overview</h4>
                <p>LLaVA-OneVision-1.5 is a fully open framework designed to democratize multimodal training. It provides a comprehensive pipeline for training and evaluating large multimodal models.</p>
                
                <h4>My Contributions</h4>
                <ul>
                    <li><b>Team Leader</b> of the project, leading the overall development and coordination</li>
                    <li>Released <a href="https://huggingface.co/collections/lmms-lab/llava-onevision-15-68d385fe73b50bd22de23713" target="_blank"><b>mid-training and instruct data</b></a> for community use</li>
                    <li>Developed <a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5/tree/main/examples_offline_packing" target="_blank"><b>offline sampling pack</b></a> for efficient training</li>
                    <li>Implemented <a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5/tree/main/aiak_training_llm/models/llavaov_1_5" target="_blank"><b>RiceViT</b></a> with native resolution support</li>
                </ul>
                
                <h4>Key Features</h4>
                <ul>
                    <li>Fully open-source training framework for multimodal models</li>
                    <li>Efficient training with mixed-precision and distributed training support</li>
                </ul>
            </div>
            <div class="project-links">
                <a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" class="project-link primary" target="_blank">View on GitHub</a>
                <a href="https://arxiv.org/abs/2509.23661" class="project-link secondary" target="_blank">Paper</a>
            </div>
        </div>

        <!-- LLaVA-NeXT -->
        <div class="project-card">
            <div class="project-header">
                <h2 class="project-title">LLaVA-NeXT · Next-Generation LMMs</h2>
                <span class="project-stars">⭐ 4000+ Stars</span>
            </div>
            <p class="project-summary">
                Contributed to the vision module of LLaVA-NeXT, enhancing its OCR capability, optimized the visual encoder and training pipeline for text-rich images.
            </p>
            <div class="project-details">
                <h4>Project Overview</h4>
                <p>LLaVA-NeXT is the next-generation large multimodal model that significantly improves upon the original LLaVA. It features enhanced visual understanding capabilities, especially for document and text-rich images.</p>
                
                <h4>My Contributions</h4>
                <ul>
                    <li>Enhanced the <b>OCR capability</b> of the vision module for better text recognition in images</li>
                    <li>Optimized the <b>visual encoder</b> for processing text-rich and document images</li>
                </ul>
                
                <h4>Key Features</h4>
                <ul>
                    <li>Enhanced visual understanding with higher resolution support</li>
                    <li>Improved OCR and document understanding capabilities</li>
                </ul>
            </div>
            <div class="project-links">
                <a href="https://github.com/LLaVA-VL/LLaVA-NeXT" class="project-link primary" target="_blank">View on GitHub</a>
            </div>
        </div>

        <!-- UNICOM -->
        <div class="project-card">
            <div class="project-header">
                <h2 class="project-title">UNICOM · Universal Representation for Image Retrieval</h2>
                <span class="project-stars">⭐ 600+ Stars</span>
            </div>
            <p class="project-summary">
                Author and maintainer of Unicom, a universal and compact representation learning framework for large-scale image retrieval.
            </p>
            <div class="project-details">
                <h4>Project Overview</h4>
                <p>UNICOM (Universal and Compact Representation Learning) is a framework I developed for learning universal image representations. It enables efficient and accurate image retrieval at scale.</p>
                
                <h4>My Contributions</h4>
                <ul>
                    <li><b>Lead author and maintainer</b> of the entire project</li>
                    <li>Designed the novel cluster discrimination approach for representation learning</li>
                    <li>Developed the multi-label and region-based extensions (published at ECCV 2024 and ICCV 2025)</li>
                    <li>Maintained pretrained models and provided comprehensive documentation</li>
                </ul>
                
                <h4>Key Features</h4>
                <ul>
                    <li>Universal image representations that transfer across domains</li>
                    <li>State-of-the-art performance on image retrieval benchmarks</li>
                </ul>
                
                <h4>Publications</h4>
                <ul>
                    <li><b>ICLR 2023:</b> Unicom: Universal and Compact Representation Learning for Image Retrieval</li>
                    <li><b>ECCV 2024:</b> Multi-label Cluster Discrimination for Visual Representation Learning</li>
                    <li><b>ICCV 2025 (Highlight):</b> Region-based Cluster Discrimination for Visual Representation Learning</li>
                </ul>
            </div>
            <div class="project-links">
                <a href="https://github.com/deepglint/unicom" class="project-link primary" target="_blank">View on GitHub</a>
                <a href="https://arxiv.org/abs/2304.05884" class="project-link secondary" target="_blank">ICLR 2023 Paper</a>
                <a href="https://arxiv.org/abs/2407.17331" class="project-link secondary" target="_blank">ECCV 2024 Paper</a>
            </div>
        </div>

        <!-- Urban Seg -->
        <div class="project-card">
            <div class="project-header">
                <h2 class="project-title">Urban Seg · Remote Sensing Semantic Segmentation</h2>
                <span class="project-stars">⭐ 460+ Stars</span>
            </div>
            <p class="project-summary">
                A beginner-friendly repository for remote sensing semantic segmentation. It allows training with pre-trained models using just a single code file.
            </p>
            <div class="project-details">
                <h4>Project Overview</h4>
                <p>Urban Seg is an educational project I created to help beginners get started with semantic segmentation for remote sensing and satellite imagery. It emphasizes simplicity and ease of use.</p>
                
                <h4>My Contributions</h4>
                <ul>
                    <li><b>Author and maintainer</b> of the entire project</li>
                    <li>Designed the simple single-file training approach for accessibility</li>
                    <li>Integrated popular pretrained models for transfer learning</li>
                    <li>Created comprehensive tutorials and documentation</li>
                </ul>
                
                <h4>Key Features</h4>
                <ul>
                    <li>Single-file training script for quick start</li>
                    <li>Beginner-friendly with clear documentation and examples</li>
                </ul>
            </div>
            <div class="project-links">
                <a href="https://github.com/anxiangsir/urban_seg" class="project-link primary" target="_blank">View on GitHub</a>
            </div>
        </div>

        <div style="margin-top: 40px; text-align: center;">
            <a href="index.html" class="back-link">Back to Home</a>
        </div>
    </div>
</body>

</html>
