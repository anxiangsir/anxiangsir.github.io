<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Xiang An - Research Scientist, Team Lead">
    <title>Xiang An</title>
    <link rel="icon" href="assets/img/profile_pic.jpg" type="image/jpg">
    <link rel="stylesheet" href="assets/css/wikipedia.css">
</head>

<body class="wiki-simple">
    <!-- Apple-style Navigation -->
    <nav class="apple-nav">
        <div class="apple-nav-inner">
            <button class="apple-nav-toggle" aria-label="Menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <a href="index.html" class="apple-nav-logo">Xiang An</a>
            <ul class="apple-nav-links">
                <li><a href="#publications">Publications</a></li>
                <li><a href="#awards">Awards</a></li>
                <li><a href="#open-source">Open Source</a></li>
            </ul>
        </div>
    </nav>

    <!-- Mobile Menu -->
    <div class="apple-mobile-menu">
        <ul>
            <li><a href="#publications">Publications</a></li>
            <li><a href="#awards">Awards</a></li>
            <li><a href="#open-source">Open Source</a></li>
        </ul>
    </div>

    <div class="wiki-simple-container">
        <article class="wiki-article">
            <!-- Article Title -->
            <h1 id="firstHeading" class="wiki-page-title">Xiang An</h1>
            
            <div class="wiki-article-body">
                <!-- Lead Section -->
                <p><b>Xiang An</b> (Chinese: 安翔) is a <b>Research Scientist</b> and <b>Team Lead</b> of the Multimodal Large Model Group at <a href="https://github.com/deepglint" target="_blank">GlintLab</a>, specializing in <a href="#publications">computer vision</a> and multimodal large models. His current research focuses on building the <b>next-generation Vision Transformer (ViT)</b> to address urgent needs in modern <abbr title="Multimodal Large Language Models">MLLMs</abbr>. He is also the <b>#2 contributor</b> to the <a href="https://github.com/deepinsight/insightface" target="_blank">InsightFace</a> ecosystem (~27k⭐).</p>

                <!-- Publications Section -->
                <h2 id="publications"><span class="mw-headline">Selected Publications</span></h2>
                <p>The following is a selection of notable publications. For a complete list, see <a href="publications.html">All Publications</a>.</p>
                
                <ul class="wiki-pub-list" id="pub-list">
                    <!-- Publications will be loaded dynamically from YAML -->
                    <li class="wiki-loading">
                        <span class="wiki-loading-spinner"></span>
                        Loading publications...
                    </li>
                </ul>

                <!-- Awards Section -->
                <h2 id="awards"><span class="mw-headline">Awards & Competitions</span></h2>
                <ul class="wiki-list">
                    <li><b>ICCV 2025 Outstanding Reviewer</b></li>
                    <li><b>CVPR 2024 Outstanding Reviewer</b></li>
                    <li><b>Ranked 1st in NIST FRVT Competition, Visa Track 1:1</b></li>
                    <li><b>2024 中国年度力量人物提名</b></li>
                    <li><b>Ranked 1st in the graduate entrance examination (major)</b></li>
                    <li><b>First Place in Vehicle Re-Identification, PRCV 2019</b></li>
                </ul>

                <!-- Open Source Section -->
                <h2 id="open-source"><span class="mw-headline">Open Source</span></h2>
                
                <h3 id="insightface"><a href="https://github.com/deepinsight/insightface" target="_blank">InsightFace</a> <span class="stars-insightface"></span></h3>
                <p>#2 contributor to the open-source 2D & 3D deep face analysis library with more than 27,000 stars on GitHub. Author of Glint360K (the largest open-source face recognition training dataset) and Partial FC (enabling training 10 million identities on a single machine). Also organized the ICCV 2021 Workshop on masked face recognition challenge.</p>
                
                <h3 id="llava-onevision"><a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" target="_blank">LLaVA-OneVision-1.5</a> <span class="stars-llava-onevision"></span></h3>
                <p>Team Leader of this fully open framework designed to democratize multimodal training. Released mid-training and instruct data for community use, and developed offline sampling pack for efficient training. Implemented RiceViT with native resolution support.</p>
                
                <h3 id="unicom"><a href="https://github.com/deepglint/unicom" target="_blank">UNICOM</a> <span class="stars-unicom"></span></h3>
                <p>Lead author and maintainer of Universal and Compact Representation Learning framework for universal image representations. Designed the novel cluster discrimination approach for representation learning. Developed the multi-label and region-based extensions (published at ECCV 2024 and ICCV 2025 (Highlight)).</p>
                
                <h3 id="llava-next"><a href="https://github.com/LLaVA-VL/LLaVA-NeXT" target="_blank">LLaVA-NeXT</a> <span class="stars-llava-next"></span></h3>
                <p>Vision module contributor to the next-generation large multimodal model. Enhanced the OCR capability of the vision module for better text recognition in images. Optimized the visual encoder for processing text-rich and document images.</p>
                
                <h3 id="urban-seg"><a href="https://github.com/anxiangsir/urban_seg" target="_blank">Urban Seg</a> <span class="stars-urban-seg"></span></h3>
                <p>Author and maintainer of this educational project for semantic segmentation on remote sensing and satellite imagery. Designed a simple single-file training approach for accessibility and integrated popular pretrained models. Created comprehensive tutorials and documentation for beginners.</p>

                <!-- External Links Section -->
                <h2 id="external-links"><span class="mw-headline">External Links</span></h2>
                <ul class="wiki-list">
                    <li><a href="mailto:anxiangsir@outlook.com">Email: anxiangsir@outlook.com</a></li>
                    <li><a href="https://scholar.google.com.hk/citations?user=1ckaPgwAAAAJ&hl=en" target="_blank">Google Scholar Profile</a></li>
                    <li><a href="https://github.com/anxiangsir" target="_blank">GitHub: anxiangsir</a></li>
                    <li><a href="https://github.com/deepinsight/insightface" target="_blank">InsightFace Project</a></li>
                </ul>
            </div>
        </article>
    </div>

    <!-- Footer -->
    <footer class="wiki-footer">
        <div class="wiki-footer-inner">
            <p>© Xiang An. Last modified: <span id="last-modified">2025</span></p>
        </div>
    </footer>

    <!-- Navigation script -->
    <script src="assets/js/navigation.js"></script>

    <!-- Load custom YAML parser -->
    <script src="assets/js/yaml-parser.js"></script>
    
    <!-- Load publications from YAML -->
    <script src="assets/js/publications-loader.js"></script>

    <!-- Load GitHub star counts dynamically -->
    <script src="assets/js/github-stars.js"></script>
</body>

</html>
