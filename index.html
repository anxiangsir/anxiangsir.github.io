<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ÂÆâÁøî's home page">
    <title>ÂÆâÁøî's Homepage</title>
    <link rel="icon" href="assets/img/profile_pic.jpg" type="image/jpg">
    <style>
        :root {
            --primary-color: #2563eb;
            --primary-hover: #1d4ed8;
            --text-dark: #1f2937;
            --text-gray: #4b5563;
            --text-light: #6b7280;
            --bg-page: #ffffff;
            --bg-card: #ffffff;
            --border-color: #e5e7eb;
        }

        body {
            font-family: "Times New Roman", Georgia, serif;
            color: var(--text-dark);
            background-color: var(--bg-page);
            margin: 0;
            padding: 80px 20px 40px 20px;
            line-height: 1.6;
            font-weight: 400;
        }

        /* ‰∏ªÂÆπÂô®ÔºöÁÆÄÊ¥ÅÂ≠¶ÊúØÈ£éÊ†º */
        #layout-content {
            margin: 0 auto;
            max-width: 850px;
            background-color: var(--bg-card);
            padding: 40px 50px;
        }

        /* Â§¥ÈÉ®Âå∫Âüü */
        .top-section {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 24px;
            gap: 24px;
        }

        .profile-info h1 {
            font-size: 2.2rem;
            margin: 0 0 8px 0;
            color: var(--text-dark);
            font-weight: 700;
        }

        .profile-info h3 {
            font-weight: 400;
            color: var(--text-gray);
            margin: 0 0 16px 0;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .profile-pic {
            width: 160px;
            height: 160px;
            border-radius: 4px;
            object-fit: cover;
            border: 1px solid var(--border-color);
            flex-shrink: 0;
        }

        /* ËÅîÁ≥ª‰ø°ÊÅØÂå∫Âüü */
        .contact-info {
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 12px;
            font-size: 0.95rem;
            color: var(--text-light);
        }

        .contact-info a {
            color: var(--primary-color);
            text-decoration: none;
        }

        .contact-info a:hover {
            text-decoration: underline;
        }

        .contact-separator {
            color: var(--text-light);
            margin: 0 4px;
        }

        /* Ê†áÈ¢òÊ†∑Âºè */
        h2 {
            font-size: 1.5rem;
            color: var(--text-dark);
            border-bottom: 2px solid var(--text-dark);
            padding-bottom: 8px;
            margin-top: 40px;
            margin-bottom: 20px;
            font-weight: 700;
        }

        p {
            color: var(--text-gray);
            margin-bottom: 16px;
            font-size: 1rem;
            line-height: 1.7;
        }

        b {
            color: var(--text-dark);
            font-weight: 600;
        }

        /* ÂàóË°®Ê†∑Âºè */
        .pub-list {
            list-style: none;
            padding: 0;
            display: flex;
            flex-direction: column;
            gap: 16px;
        }

        /* Âç°ÁâáÊ†∑ÂºèÔºöÁÆÄÊ¥ÅÂ≠¶ÊúØÈ£éÊ†º */
        .publication-entry {
            display: flex;
            padding: 16px;
            border: 1px solid var(--border-color);
            background: var(--bg-card);
        }

        .publication-entry img {
            width: 160px;
            height: 90px;
            margin-right: 20px;
            object-fit: cover;
            background-color: #f9fafb;
            border: 1px solid var(--border-color);
            flex-shrink: 0;
        }

        .pub-content {
            flex: 1;
        }

        .pub-title {
            font-size: 1rem;
            font-weight: 600;
            color: var(--text-dark);
            margin-bottom: 6px;
            display: block;
            line-height: 1.4;
        }

        .pub-authors {
            color: var(--text-light);
            font-size: 0.9rem;
            margin-bottom: 6px;
            display: block;
            line-height: 1.5;
        }

        .pub-venue {
            color: var(--text-dark);
            font-weight: 600;
            font-size: 0.85rem;
            display: inline-block;
            background: #f3f4f6;
            padding: 4px 10px;
        }

        /* ÈìæÊé•ÊåâÈíÆÊ†∑Âºè [Paper] [Code] */
        .link-badges {
            display: flex;
            gap: 8px;
            margin-top: 4px;
        }

        .badge-link {
            display: inline-flex;
            align-items: center;
            padding: 4px 10px;
            font-size: 0.8rem;
            font-weight: 500;
            color: #fff;
            background: var(--primary-color);
            text-decoration: none;
        }

        .badge-link:hover {
            background: var(--primary-hover);
            text-decoration: none;
        }

        /* È´ò‰∫Æ‰ΩúËÄÖÂêç */
        .me-highlight {
            color: var(--primary-color);
            font-weight: 600;
            text-decoration: none;
        }

        /* Â•ñÈ°πÂàóË°® */
        .awards-list li {
            padding: 10px 0;
            display: flex;
            align-items: center;
            color: var(--text-dark);
            border-bottom: 1px solid var(--border-color);
        }

        .awards-list li:last-child {
            border-bottom: none;
        }

        .awards-list .emoji {
            margin-right: 12px;
            font-size: 1.2em;
        }

        /* Site Header - ‰øùÁïôÂØºËà™Ê†èÊ†∑Âºè */
        .site-header {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 52px;
            background-color: rgba(255, 255, 255, 0.95);
            backdrop-filter: saturate(180%) blur(20px);
            -webkit-backdrop-filter: saturate(180%) blur(20px);
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0 32px;
            box-sizing: border-box;
            z-index: 1000;
            border-bottom: 1px solid var(--border-color);
        }

        .header-logo {
            font-size: 1.1rem;
            font-weight: 600;
            color: var(--text-dark);
            text-decoration: none;
        }

        .header-logo:hover {
            color: var(--primary-color);
        }

        .site-nav {
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .nav-link {
            font-size: 0.85rem;
            font-weight: 400;
            color: var(--text-dark);
            text-decoration: none;
            padding: 8px 14px;
            border-radius: 4px;
        }

        .nav-link:hover {
            background-color: #f3f4f6;
            color: var(--text-dark);
        }

        .nav-link:active {
            background-color: #e5e7eb;
        }

        /* ÁßªÂä®Á´ØÈÄÇÈÖç */
        @media (max-width: 768px) {
            body {
                padding: 68px 0 0 0;
                background-color: #fff;
            }

            .site-header {
                padding: 0 16px;
                height: 48px;
            }

            .header-logo {
                font-size: 1rem;
            }

            #layout-content {
                padding: 24px 16px;
                width: auto;
                margin: 0;
            }

            .top-section {
                flex-direction: column-reverse;
                align-items: center;
                text-align: center;
            }

            .profile-info {
                max-width: 100% !important;
            }

            .profile-info h1 {
                font-size: 1.8rem;
            }

            .profile-info h3 {
                justify-content: center;
            }

            .contact-info {
                justify-content: center;
            }

            h2 {
                font-size: 1.3rem;
                margin-top: 32px;
            }

            .publication-entry {
                flex-direction: column;
                padding: 16px;
            }

            .publication-entry img {
                width: 100%;
                height: auto;
                margin-right: 0;
                margin-bottom: 12px;
            }
        }

        /* Mobile hamburger menu */
        .nav-toggle {
            display: none;
            background: none;
            border: none;
            cursor: pointer;
            padding: 8px;
            z-index: 1002;
        }

        .nav-toggle span {
            display: block;
            width: 22px;
            height: 2px;
            background-color: #1f2937;
            margin: 5px 0;
            transition: transform 0.3s ease, opacity 0.3s ease;
        }

        .nav-toggle.active span:nth-child(1) {
            transform: rotate(45deg) translate(5px, 5px);
        }

        .nav-toggle.active span:nth-child(2) {
            opacity: 0;
        }

        .nav-toggle.active span:nth-child(3) {
            transform: rotate(-45deg) translate(5px, -5px);
        }

        /* Mobile navigation overlay */
        .nav-overlay {
            display: none;
            position: fixed;
            top: 48px;
            left: 0;
            width: 100%;
            height: calc(100vh - 48px);
            background-color: rgba(255, 255, 255, 0.98);
            z-index: 999;
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        .nav-overlay.active {
            display: block;
            opacity: 1;
        }

        .mobile-nav {
            display: none;
            flex-direction: column;
            padding: 20px 24px;
        }

        .mobile-nav .nav-link {
            font-size: 1rem;
            padding: 14px 0;
            border-bottom: 1px solid var(--border-color);
            border-radius: 0;
        }

        .mobile-nav .nav-link:last-child {
            border-bottom: none;
        }

        .mobile-nav .nav-link:hover {
            background-color: transparent;
            color: var(--primary-color);
        }

        /* Mobile responsive */
        @media (max-width: 768px) {
            .nav-toggle {
                display: block;
            }

            .site-nav {
                display: none;
            }

            .nav-overlay.active .mobile-nav {
                display: flex;
            }
        }


        /*
           ========================================
           ÊâìÂç∞‰∏ìÁî®Ê†∑Âºè (‰ºòÂåñÂÆΩÂ∫¶‰∏éÂàÜÈ°µ)
           ========================================
        */
        @media print {
            /* Hide the fixed header when printing */
            .site-header {
                display: none;
            }

            /* 1. ËÆæÁΩÆÊâìÂç∞È°µÈù¢ÁöÑËæπË∑ù */
            @page {
                margin: 1cm 1cm;
                size: auto;
            }

            /* 2. ÈáçÁΩÆ Body ÁöÑËæπË∑ùÂíåÂÜÖËæπË∑ùÔºåÁ°Æ‰øùÂà©Áî®ÂÖ®ÈÉ®ÂÆΩÂ∫¶ */
            body {
                background-color: #fff;
                padding: 0;
                margin: 0;
            }

            /* 3. ÈáçÁΩÆ‰∏ªÂÆπÂô®ÁöÑÊ†∑Âºè */
            #layout-content {
                margin: 0;
                width: 100%;
                max-width: none !important;
                padding: 0;
                border: none;
            }

            /* 4. Â≠ó‰ΩìÂæÆË∞É */
            .profile-info h1 {
                font-size: 1.8rem;
            }

            /* 5. Ê†∏ÂøÉÂàÜÈ°µÊéßÂà∂ÔºöÈò≤Ê≠¢ÂÖÉÁ¥†ÂÜÖÈÉ®Êñ≠È°µ */
            .publication-entry,
            .top-section,
            h2,
            .contact-box,
            li {
                break-inside: avoid;
                page-break-inside: avoid;
            }

            /* Èò≤Ê≠¢Ê†áÈ¢ò‰∏é‰∏ãÊñπÂÜÖÂÆπÂàÜÁ¶ª */
            h2 {
                break-after: avoid;
                page-break-after: avoid;
                margin-top: 20px;
            }
        }

    </style>
</head>

<body>

    <!-- Site Header (Meta-style fixed navigation) -->
    <header class="site-header">
        <nav class="site-nav">
            <a href="#publications" class="nav-link">Selected Publications</a>
            <a href="publications.html" class="nav-link">All Publications</a>
            <a href="community.html" class="nav-link">Community Contribution</a>
            <a href="#awards" class="nav-link">Awards & Competitions</a>
        </nav>
        <button class="nav-toggle" aria-label="Toggle navigation">
            <span></span>
            <span></span>
            <span></span>
        </button>
    </header>

    <!-- Mobile Navigation Overlay -->
    <div class="nav-overlay">
        <nav class="mobile-nav">
            <a href="#publications" class="nav-link">Publications</a>
            <a href="publications.html" class="nav-link">All Pubs</a>
            <a href="community.html" class="nav-link">Community</a>
            <a href="#awards" class="nav-link">Awards</a>
        </nav>
    </div>

    <script>
        // Mobile navigation toggle
        document.addEventListener('DOMContentLoaded', function() {
            const navToggle = document.querySelector('.nav-toggle');
            const navOverlay = document.querySelector('.nav-overlay');
            const mobileNavLinks = document.querySelectorAll('.mobile-nav .nav-link');

            navToggle.addEventListener('click', function() {
                navToggle.classList.toggle('active');
                navOverlay.classList.toggle('active');
                document.body.style.overflow = navOverlay.classList.contains('active') ? 'hidden' : '';
            });

            // Close menu when clicking a link
            mobileNavLinks.forEach(function(link) {
                link.addEventListener('click', function() {
                    navToggle.classList.remove('active');
                    navOverlay.classList.remove('active');
                    document.body.style.overflow = '';
                });
            });

            // Close menu when clicking overlay background
            navOverlay.addEventListener('click', function(e) {
                if (e.target === navOverlay) {
                    navToggle.classList.remove('active');
                    navOverlay.classList.remove('active');
                    document.body.style.overflow = '';
                }
            });
        });
    </script>

    <div id="layout-content">
        <div class="top-section">
            <div class="profile-info" style="max-width: 70%;">
                <h1>Xiang An</h1>
                <div class="contact-info">
                    <a href="mailto:anxiangsir@outlook.com" title="anxiangsir@outlook.com">Mail</a>
                    <span class="contact-separator">¬∑</span>
                    <a href="https://scholar.google.com.hk/citations?user=1ckaPgwAAAAJ&hl=en" target="_blank">Google Scholar</a>
                    <span class="contact-separator">¬∑</span>
                    <a href="https://github.com/anxiangsir" target="_blank">GitHub</a>
                </div>
            </div>
            <div>
                <img class="profile-pic" src="assets/img/profile_pic.jpg" alt="Xiang An">
            </div>
        </div>

        <h2 id="about">About Me</h2>
        <p>
            I am an <b>Research Scientist</b> and <b>Team Lead</b> of the Multimodal Large Model Group at <b>GlintLab</b>, focusing on computer vision and multimodal large models.
        </p>
        <p>
            Currently, our team is building the <b>next-generation Vision Transformer (ViT)</b> to address some of the most urgent needs in modern MLLMs.
        </p>

        <h2 id="publications">Selected Publications</h2>
        <ul class="pub-list">
            <li>
                <div class="publication-entry">
                    <!-- ËøôÈáåÁöÑÂõæÁâá src Â¶ÇÊûúÊòØÁ©∫ÁöÑÊàñËÄÖÂä†ËΩΩÂ§±Ë¥•‰ºöÊòæÁ§∫ËÉåÊôØËâ≤Âç†‰Ωç -->
                    <img src="assets/img/publication_preview_1.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Llava-OneVision-1.5: Fully open framework for democratized multimodal training</span>
                        <span class="pub-authors">
                            <span class="me-highlight">Xiang An</span>, Yin Xie, Kaicheng Yang, Wenkang Zhang, Xiuwei Zhao, Zheng Cheng, Yirui Wang, Songcen Xu, Changrui Chen, Chunsheng Wu, Huajie Tan, Chunyuan Li, Jing Yang, Jie Yu, Xiyao Wang, Bin Qin, Yumeng Wang, Zizhen Yan, Ziyong Feng, Ziwei Liu, Bo Li, Jiankang Deng
                        </span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2509.23661" class="badge-link">Paper</a>
                            <a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" class="badge-link">Code</a>
                            <span class="pub-venue">Preprint, 2025</span>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_2.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning</span>
                        <span class="pub-authors">
                            Tiancheng Gu, Kaicheng Yang, Kaichen Zhang, <span class="me-highlight">Xiang An</span>, Ziyong Feng, Yueyi Zhang, Weidong Cai, Jiankang Deng, Lidong Bing
                        </span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/pdf/2510.13515" class="badge-link">Paper</a>
                            <a href="https://github.com/GaryGuTC/UniME-v2" class="badge-link">Code</a>
                            <span class="pub-venue">AAAI, 2026 (Oral)</span>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_3.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Region-based Cluster Discrimination for Visual Representation Learning</span>
                        <span class="pub-authors">
                            Yin Xie, Kaicheng Yang, <span class="me-highlight">Xiang An (Project Leader)</span>, Kun Wu, Yongle Zhao, Weimo Deng, Zimin Ran, Yumeng Wang, Ziyong Feng, Roy Miles, Ismail Elezi, Jiankang Deng
                        </span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2507.20025" class="badge-link">Paper</a>
                            <a href="https://github.com/deepglint/unicom" class="badge-link">Code</a>
                            <span class="pub-venue">ICCV, 2025 (Highlight)</span>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_4.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Multi-label Cluster Discrimination for Visual Representation Learning</span>
                        <span class="pub-authors">
                            <span class="me-highlight">Xiang An</span>, Kaicheng Yang, Xiangzi Dai, Ziyong Feng, Jiankang Deng
                        </span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2407.17331" class="badge-link">Paper</a>
                            <a href="https://github.com/deepglint/unicom" class="badge-link">Code</a>
                            <span class="pub-venue">ECCV, 2024</span>
                        </div>
                    </div>
                </div>
            </li>

             <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_5.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Unicom: Universal and Compact Representation Learning for Image Retrieval</span>
                        <span class="pub-authors">
                             <span class="me-highlight">Xiang An</span>, Jiankang Deng, Kaicheng Yang, Jiawei Li, Ziyong Feng, Jia Guo, Jing Yang, Tongliang Liu
                        </span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2304.05884" class="badge-link">Paper</a>
                            <a href="https://github.com/deepglint/unicom" class="badge-link">Code</a>
                            <span class="pub-venue">ICLR, 2023</span>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_6.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Killing Two Birds with One Stone: Efficient and Robust Training of Face Recognition CNNs by Partial FC</span>
                        <span class="pub-authors">
                            <span class="me-highlight">Xiang An</span>, Jiankang Deng, Jia Guo, Ziyong Feng, Xuhan Zhu, Jing Yang, Tongliang Liu
                        </span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2203.15565" class="badge-link">Paper</a>
                            <a href="https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch" class="badge-link">Code</a>
                            <span class="pub-venue">CVPR, 2022</span>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_7.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Partial FC: Training 10 million identities on a single machine</span>
                        <span class="pub-authors">
                            <span class="me-highlight">Xiang An</span>, Xuhan Zhu, Yuan Gao, Yang Xiao, Yongle Zhao, Ziyong Feng, Lan Wu, Bin Qin, Ming Zhang, Debing Zhang, Ying Fu
                        </span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2010.05222" class="badge-link">Paper</a>
                            <a href="https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch" class="badge-link">Code</a>
                            <span class="pub-venue">ICCVW, 2021</span>
                        </div>
                    </div>
                </div>
            </li>
        </ul>

        <h2 id="community">Community Contribution</h2>
        <p>I actively contribute to open-source projects in face recognition, representation learning, and multimodal large models. I am the <b>#2 contributor</b> to the <b>InsightFace</b> ecosystem (~27k‚≠ê), and co-maintain several influential vision and multimodal repositories.</p>

        <ul class="pub-list">
            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">InsightFace ¬∑ 2D & 3D Face Analysis Toolkit</span>
                        <span class="pub-authors">
                            Major contributor (#2 by contributions) to the core InsightFace ecosystem for large-scale face recognition and analysis.
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                            <a href="https://github.com/deepinsight/insightface" class="badge-link" target="_blank">‚≠ê 27k+ Stars</a>
                            <a href="https://github.com/deepinsight/insightface" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">LLaVA-OneVision-1.5 ¬∑ Multimodal Training Framework</span>
                        <span class="pub-authors">
                            Fully open framework for democratized multimodal training, advancing large multimodal models (LMMs).
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                             <a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" class="badge-link" target="_blank">‚≠ê 600+ Stars</a>
                             <a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">LLaVA-NeXT ¬∑ Next-Generation LMMs</span>
                        <span class="pub-authors">
                            Contributed to the vision module of LLaVA-NeXT, enhancing its OCR capability, optimized the visual encoder and training pipeline for text-rich images.
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                             <a href="https://github.com/LLaVA-VL/LLaVA-NeXT" class="badge-link" target="_blank">‚≠ê 4000+ Stars</a>
                             <a href="https://github.com/LLaVA-VL/LLaVA-NeXT" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">UNICOM ¬∑ Universal Representation for Image Retrieval</span>
                        <span class="pub-authors">
                            Author and maintainer of <b>Unicom</b>, a universal and compact representation learning framework for large-scale image retrieval.
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                             <a href="https://github.com/deepglint/unicom" class="badge-link" target="_blank">‚≠ê 600+ Stars</a>
                             <a href="https://github.com/deepglint/unicom" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">Urban Seg ¬∑ Remote Sensing Semantic Segmentation</span>
                        <span class="pub-authors">
                            A beginner-friendly repository for remote sensing semantic segmentation. It allows training with pre-trained models using just a single code file.
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                             <a href="https://github.com/anxiangsir/urban_seg" class="badge-link" target="_blank">‚≠ê 460+ Stars</a>
                             <a href="https://github.com/anxiangsir/urban_seg" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>
        </ul>

        <h2 id="awards">Awards & Competitions</h2>
        <ul class="awards-list" style="list-style-type: none; padding-left: 0;">
            <li><span class="emoji">üèÖ</span> <b>ICCV 2025 Outstanding Reviewer</b></li>
            <li><span class="emoji">üèÖ</span> <b>CVPR 2024 Outstanding Reviewer</b></li>
            <li><span class="emoji">üèÜ</span> <b>Randed 1st in NIST FRVT Competition, Visa Track 1:1</b></li>
            <li><span class="emoji">üèÜ</span> <b>2024 ‰∏≠ÂõΩÂπ¥Â∫¶ÂäõÈáè‰∫∫Áâ©ÊèêÂêç</b></li>
            <li><span class="emoji">üèÜ</span> <b>Ranked 1st in the graduate entrance examination (major)</b></li>
            <li><span class="emoji">üèÜ</span> <b>First Place in Vehicle Re-Identification, PRCV 2019</b></li>
        </ul>

    </div>
</body>

</html>