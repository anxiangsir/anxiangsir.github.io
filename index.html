<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="å®‰ç¿”'s home page">
    <title>å®‰ç¿”'s Homepage</title>
    <link rel="icon" href="assets/img/profile_pic.jpg" type="image/jpg">
    <style>
        :root {
            --primary-color: #297be6;
            --text-dark: #1f2937;
            --text-gray: #4b5563;
            --text-light: #6b7280;
            --bg-page: #f3f4f6;
            --bg-card: #ffffff;
            --border-color: #e5e7eb;
            --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
            --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
            color: var(--text-dark);
            background-color: var(--bg-page);
            margin: 0;
            padding: 40px 20px;
            line-height: 1.6;
        }

        /* ä¸»å®¹å™¨ï¼šå¢åŠ çº¸å¼ è´¨æ„Ÿ */
        #layout-content {
            margin: 0 auto;
            max-width: 900px;
            background-color: var(--bg-card);
            padding: 48px;
            border-radius: 16px;
            box-shadow: var(--shadow-lg);
        }

        /* å¤´éƒ¨åŒºåŸŸ */
        .top-section {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 40px;
            gap: 24px;
        }

        .profile-info h1 {
            font-size: 2.5rem;
            margin: 0 0 8px 0;
            color: #111827;
            letter-spacing: -0.025em;
        }

        .profile-info h3 {
            font-weight: 500;
            color: var(--text-gray);
            margin: 0 0 16px 0;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .profile-pic {
            width: 180px;
            height: 180px;
            border-radius: 50%;
            object-fit: cover;
            box-shadow: var(--shadow-md);
            border: 4px solid #fff;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            flex-shrink: 0;
        }

        .profile-pic:hover {
            transform: scale(1.02) rotate(2deg);
            box-shadow: var(--shadow-lg);
        }

        /* è”ç³»æ–¹å¼æ¡†ä¼˜åŒ– */
        .contact-box {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            margin-top: 16px;
        }

        .contact-link {
            display: inline-flex;
            align-items: center;
            background: #f9fafb;
            border: 1px solid var(--border-color);
            padding: 6px 12px;
            border-radius: 20px;
            font-size: 0.9em;
            color: var(--text-gray);
            text-decoration: none;
            transition: all 0.2s;
        }

        .contact-link:hover {
            background: #eff6ff;
            border-color: var(--primary-color);
            color: var(--primary-color);
        }

        .contact-link img {
            width: 16px;
            height: 16px;
            margin-right: 8px;
            opacity: 0.8;
        }

        /* æ ‡é¢˜æ ·å¼ */
        h2 {
            font-size: 1.5rem;
            color: #111827;
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 12px;
            margin-top: 48px;
            margin-bottom: 24px;
        }

        p {
            color: var(--text-gray);
            margin-bottom: 16px;
        }

        b {
            color: var(--text-dark);
            font-weight: 600;
        }

        /* åˆ—è¡¨æ ·å¼ */
        .pub-list {
            list-style: none;
            padding: 0;
            display: flex;
            flex-direction: column;
            gap: 20px;
        }

        /* å¡ç‰‡æ ·å¼ä¼˜åŒ– */
        .publication-entry {
            display: flex;
            padding: 20px;
            border-radius: 12px;
            background: #fff;
            border: 1px solid var(--border-color);
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }

        .publication-entry:hover {
            transform: translateY(-2px);
            box-shadow: var(--shadow-md);
            border-color: #d1d5db;
        }

        .publication-entry img {
            width: 180px;
            height: 100px;
            border-radius: 8px;
            margin-right: 20px;
            object-fit: cover;
            background-color: #f3f4f6; /* å›¾ç‰‡åŠ è½½å‰çš„å ä½è‰² */
            border: 1px solid #f3f4f6;
            flex-shrink: 0;
        }

        .pub-content {
            flex: 1;
        }

        .pub-title {
            font-size: 1.1rem;
            font-weight: 700;
            color: #111827;
            margin-bottom: 6px;
            display: block;
            line-height: 1.4;
        }

        .pub-authors {
            color: var(--text-light);
            font-size: 0.95rem;
            margin-bottom: 6px;
            display: block;
        }

        .pub-venue {
            color: #000;
            font-weight: 600;
            font-size: 0.9rem;
            margin-bottom: 10px;
            display: inline-block;
        }

        /* èƒ¶å›ŠæŒ‰é’®æ ·å¼ [Paper] [Code] */
        .link-badges {
            display: flex;
            gap: 8px;
            margin-top: 4px;
        }

        .badge-link {
            display: inline-flex;
            align-items: center;
            padding: 4px 10px;
            font-size: 0.8rem;
            font-weight: 600;
            color: var(--primary-color);
            background-color: #eff6ff;
            border-radius: 6px;
            text-decoration: none;
            transition: background-color 0.2s;
        }

        .badge-link:hover {
            background-color: #dbeafe;
            text-decoration: none;
        }

        /* é«˜äº®ä½œè€…å */
        .me-highlight {
            color: var(--primary-color);
            font-weight: 600;
            text-decoration: underline;
            text-underline-offset: 2px;
        }

        /* å¥–é¡¹åˆ—è¡¨ */
        .awards-list li {
            padding: 8px 0;
            display: flex;
            align-items: center;
            color: var(--text-dark);
        }

        .awards-list .emoji {
            margin-right: 12px;
            font-size: 1.2em;
        }

        /* Navigation styles */
        .site-nav {
            display: flex;
            justify-content: center;
            gap: 32px;
            margin-bottom: 8px;
            padding: 12px 0;
        }

        .nav-link {
            font-size: 0.95rem;
            font-weight: 500;
            color: var(--text-gray);
            text-decoration: none;
            padding: 8px 0;
            position: relative;
            transition: color 0.2s ease;
        }

        .nav-link:hover {
            color: var(--primary-color);
        }

        .nav-link::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 0;
            height: 2px;
            background: var(--primary-color);
            transition: width 0.2s ease;
        }

        .nav-link:hover::after {
            width: 100%;
        }

        /* ç§»åŠ¨ç«¯é€‚é… */
        @media (max-width: 768px) {
            #layout-content {
                padding: 24px 20px;
                width: auto;
                margin: 0;
                border-radius: 0;
                box-shadow: none;
            }

            body {
                padding: 0;
                background-color: #fff;
            }

            .top-section {
                flex-direction: column-reverse;
                align-items: center;
                text-align: center;
            }

            .profile-info {
                max-width: 100% !important;
            }

            .profile-info h3 {
                justify-content: center;
            }

            .contact-box {
                justify-content: center;
            }

            .site-nav {
                gap: 16px;
            }

            .nav-link {
                font-size: 0.85rem;
            }

            .publication-entry {
                flex-direction: column;
            }

            .publication-entry img {
                width: 100%;
                height: auto;
                margin-right: 0;
                margin-bottom: 16px;
            }
        }


        /*
           ========================================
           æ‰“å°ä¸“ç”¨æ ·å¼ (ä¼˜åŒ–å®½åº¦ä¸åˆ†é¡µ)
           ========================================
        */
        @media print {
            /* 1. è®¾ç½®æ‰“å°é¡µé¢çš„è¾¹è· */
            @page {
                margin: 1cm 1cm; /* ä¸Šä¸‹1cmï¼Œå·¦å³1cm */
                size: auto;
            }

            /* 2. é‡ç½® Body çš„è¾¹è·å’Œå†…è¾¹è·ï¼Œç¡®ä¿åˆ©ç”¨å…¨éƒ¨å®½åº¦ */
            body {
                background-color: #fff;
                padding: 0;
                margin: 0;
                -webkit-print-color-adjust: exact; /* å°½å¯èƒ½ä¿ç•™èƒŒæ™¯è‰²ï¼ˆå¦‚éœ€è¦ï¼‰ */
            }

            /* 3. é‡ç½®ä¸»å®¹å™¨çš„æ ·å¼ï¼šå»æ‰æœ€å¤§å®½åº¦é™åˆ¶ã€é˜´å½±ã€è¾¹æ¡†å’Œå†…è¾¹è· */
            #layout-content {
                box-shadow: none;
                margin: 0;
                width: 100%;
                max-width: none !important; /* å¼ºåˆ¶è¦†ç›– 900px é™åˆ¶ */
                padding: 0;                 /* ç§»é™¤å®¹å™¨å†…è¾¹è·ï¼Œè®©å†…å®¹æ›´å®½ */
                border: none;
                border-radius: 0;
            }

            /* 4. å­—ä½“å¾®è°ƒï¼ˆå¯é€‰ï¼Œé˜²æ­¢æ‰“å°å­—ä½“è¿‡å¤§ï¼‰ */
            .profile-info h1 {
                font-size: 2rem;
            }

            /* 5. æ ¸å¿ƒåˆ†é¡µæ§åˆ¶ï¼šé˜²æ­¢å…ƒç´ å†…éƒ¨æ–­é¡µ */
            .publication-entry,
            .top-section,
            h2,
            .contact-box,
            li {
                break-inside: avoid;
                page-break-inside: avoid;
            }

            /* é˜²æ­¢æ ‡é¢˜ä¸ä¸‹æ–¹å†…å®¹åˆ†ç¦» */
            h2 {
                break-after: avoid;
                page-break-after: avoid;
                margin-top: 20px; /* æ‰“å°æ—¶ç¨å¾®å‡å°‘é¡¶éƒ¨é—´è· */
            }

            /* 6. éšè—ä¸éœ€è¦æ‰“å°çš„å…ƒç´ ï¼ˆå¯é€‰ï¼Œå¦‚æœéœ€è¦çš„è¯ï¼‰ */
            /* .no-print { display: none; } */
        }

    </style>
</head>

<body>

    <div id="layout-content">
        <div class="top-section">
            <div class="profile-info" style="max-width: 70%;">
                <h1>Xiang An (å®‰ç¿”)</h1>
                <h3><span class="emoji">ğŸ“</span> Algorithm Engineer</h3>
                <div class="contact-box">
                    <a href="mailto:anxiangsir@outlook.com" class="contact-link">
                        <img src="assets/img/envelope.png" alt="Email">Email
                    </a>
                    <a href="https://scholar.google.com.hk/citations?user=1ckaPgwAAAAJ&hl=en" target="_blank" class="contact-link">
                        <img src="assets/img/google.png" alt="Google Scholar">Scholar
                    </a>
                    <a href="https://github.com/anxiangsir" target="_blank" class="contact-link">
                        <img src="assets/img/github.png" alt="GitHub">GitHub
                    </a>
                </div>
            </div>
            <div>
                <img class="profile-pic" src="assets/img/profile_pic.jpg" alt="Xiang An">
            </div>
        </div>

        <!-- Navigation -->
        <nav class="site-nav">
            <a href="#publications" class="nav-link">Selected Publications</a>
            <a href="publications.html" class="nav-link">All Publications</a>
            <a href="#community" class="nav-link">Community Contribution</a>
            <a href="#awards" class="nav-link">Awards & Competitions</a>
        </nav>

        <h2 id="about">About Me</h2>
        <p>
            I am an <b>Research Scientist</b> and <b>Team Lead</b> of the Multimodal Large Model Group at <b>GlintLab</b>, focusing on computer vision and multimodal large models.
        </p>
        <p>
            Currently, our team is building the <b>next-generation Vision Transformer (ViT)</b> to address some of the most urgent needs in modern MLLMs.
        </p>

        <h2 id="publications">Selected Publications</h2>
        <ul class="pub-list">
            <li>
                <div class="publication-entry">
                    <!-- è¿™é‡Œçš„å›¾ç‰‡ src å¦‚æœæ˜¯ç©ºçš„æˆ–è€…åŠ è½½å¤±è´¥ä¼šæ˜¾ç¤ºèƒŒæ™¯è‰²å ä½ -->
                    <img src="assets/img/publication_preview_1.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Llava-OneVision-1.5: Fully open framework for democratized multimodal training</span>
                        <span class="pub-authors">
                            <span class="me-highlight">Xiang An</span>, Yin Xie, Kaicheng Yang, Wenkang Zhang, Ziyong Feng, Ziwei Liu, Bo Li, Jiankang Deng
                        </span>
                        <span class="pub-venue">Preprint, 2025</span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2509.23661" class="badge-link">Paper</a>
                            <a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" class="badge-link">Code</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_2.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning</span>
                        <span class="pub-authors">
                            Tiancheng Gu, Kaicheng Yang, Kaichen Zhang, <span class="me-highlight">Xiang An</span>, Ziyong Feng, Yueyi Zhang, Weidong Cai, Jiankang Deng, Lidong Bing
                        </span>
                        <span class="pub-venue">AAAI, 2026 (Oral)</span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/pdf/2510.13515" class="badge-link">Paper</a>
                            <a href="https://github.com/GaryGuTC/UniME-v2" class="badge-link">Code</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_3.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Region-based Cluster Discrimination for Visual Representation Learning</span>
                        <span class="pub-authors">
                            Yin Xie, Kaicheng Yang, <span class="me-highlight">Xiang An (Project Leader)</span>, Kun Wu, Yongle Zhao, Weimo Deng, Zimin Ran, Yumeng Wang, Ziyong Feng, Roy Miles, Ismail Elezi, Jiankang Deng
                        </span>
                        <span class="pub-venue">ICCV, 2025 (Highlight)</span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2507.20025" class="badge-link">Paper</a>
                            <a href="https://github.com/deepglint/unicom" class="badge-link">Code</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_4.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Multi-label Cluster Discrimination for Visual Representation Learning</span>
                        <span class="pub-authors">
                            <span class="me-highlight">Xiang An</span>, Kaicheng Yang, Xiangzi Dai, Ziyong Feng, Jiankang Deng
                        </span>
                        <span class="pub-venue">ECCV, 2024</span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2407.17331" class="badge-link">Paper</a>
                            <a href="https://github.com/deepglint/unicom" class="badge-link">Code</a>
                        </div>
                    </div>
                </div>
            </li>

             <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_5.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Unicom: Universal and Compact Representation Learning for Image Retrieval</span>
                        <span class="pub-authors">
                             <span class="me-highlight">Xiang An</span>, Jiankang Deng, Kaicheng Yang, Jiawei Li, Ziyong Feng, Jia Guo, Jing Yang, Tongliang Liu
                        </span>
                        <span class="pub-venue">ICLR, 2023</span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2304.05884" class="badge-link">Paper</a>
                            <a href="https://github.com/deepglint/unicom" class="badge-link">Code</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_6.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Killing Two Birds with One Stone: Efficient and Robust Training of Face Recognition CNNs by Partial FC</span>
                        <span class="pub-authors">
                            <span class="me-highlight">Xiang An</span>, Jiankang Deng, Jia Guo, Ziyong Feng, Xuhan Zhu, Jing Yang, Tongliang Liu
                        </span>
                        <span class="pub-venue">CVPR, 2022</span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2203.15565" class="badge-link">Paper</a>
                            <a href="https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch" class="badge-link">Code</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry">
                    <img src="assets/img/publication_preview_7.jpg" alt="Paper Preview" onerror="this.style.display='none'">
                    <div class="pub-content">
                        <span class="pub-title">Partial FC: Training 10 million identities on a single machine</span>
                        <span class="pub-authors">
                            <span class="me-highlight">Xiang An</span>, Xuhan Zhu, Yuan Gao, Yang Xiao, Yongle Zhao, Ziyong Feng, Lan Wu, Bin Qin, Ming Zhang, Debing Zhang, Ying Fu
                        </span>
                        <span class="pub-venue">ICCVW, 2021</span>
                        <div class="link-badges">
                            <a href="https://arxiv.org/abs/2010.05222" class="badge-link">Paper</a>
                            <a href="https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch" class="badge-link">Code</a>
                        </div>
                    </div>
                </div>
            </li>
        </ul>

        <h2 id="community">Community Contribution</h2>
        <p>I actively contribute to open-source projects in face recognition, representation learning, and multimodal large models. I am the <b>#2 contributor</b> to the <b>InsightFace</b> ecosystem (~27kâ­), and co-maintain several influential vision and multimodal repositories.</p>

        <ul class="pub-list">
            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">InsightFace Â· 2D & 3D Face Analysis Toolkit</span>
                        <span class="pub-authors">
                            Major contributor (#2 by contributions) to the core InsightFace ecosystem for large-scale face recognition and analysis.
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                            <a href="https://github.com/deepinsight/insightface" class="badge-link" target="_blank">â­ 27k+ Stars</a>
                            <a href="https://github.com/deepinsight/insightface" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">LLaVA-OneVision-1.5 Â· Multimodal Training Framework</span>
                        <span class="pub-authors">
                            Fully open framework for democratized multimodal training, advancing large multimodal models (LMMs).
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                             <a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" class="badge-link" target="_blank">â­ 600+ Stars</a>
                             <a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">LLaVA-NeXT Â· Next-Generation LMMs</span>
                        <span class="pub-authors">
                            Contributed to the vision module of LLaVA-NeXT, enhancing its OCR capability, optimized the visual encoder and training pipeline for text-rich images.
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                             <a href="https://github.com/LLaVA-VL/LLaVA-NeXT" class="badge-link" target="_blank">â­ 4000+ Stars</a>
                             <a href="https://github.com/LLaVA-VL/LLaVA-NeXT" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">UNICOM Â· Universal Representation for Image Retrieval</span>
                        <span class="pub-authors">
                            Author and maintainer of <b>Unicom</b>, a universal and compact representation learning framework for large-scale image retrieval.
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                             <a href="https://github.com/deepglint/unicom" class="badge-link" target="_blank">â­ 600+ Stars</a>
                             <a href="https://github.com/deepglint/unicom" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>

            <li>
                <div class="publication-entry" style="align-items: center;">
                    <div class="pub-content">
                        <span class="pub-title">Urban Seg Â· Remote Sensing Semantic Segmentation</span>
                        <span class="pub-authors">
                            A beginner-friendly repository for remote sensing semantic segmentation. It allows training with pre-trained models using just a single code file.
                        </span>
                        <div class="link-badges" style="margin-top: 8px;">
                             <a href="https://github.com/anxiangsir/urban_seg" class="badge-link" target="_blank">â­ 460+ Stars</a>
                             <a href="https://github.com/anxiangsir/urban_seg" class="badge-link" style="background-color: transparent; border: 1px solid var(--border-color); color: var(--text-dark);">View Repo</a>
                        </div>
                    </div>
                </div>
            </li>
        </ul>

        <h2 id="awards">Awards & Competitions</h2>
        <ul class="awards-list" style="list-style-type: none; padding-left: 0;">
            <li><span class="emoji">ğŸ…</span> <b>ICCV 2025 Outstanding Reviewer</b></li>
            <li><span class="emoji">ğŸ…</span> <b>CVPR 2024 Outstanding Reviewer</b></li>
            <li><span class="emoji">ğŸ†</span> <b>Randed 1st in NIST FRVT Competition, Visa Track 1:1</b></li>
            <li><span class="emoji">ğŸ†</span> <b>2024 ä¸­å›½å¹´åº¦åŠ›é‡äººç‰©æå</b></li>
            <li><span class="emoji">ğŸ†</span> <b>Ranked 1st in the graduate entrance examination (major)</b></li>
            <li><span class="emoji">ğŸ†</span> <b>First Place in Vehicle Re-Identification, PRCV 2019</b></li>
        </ul>

    </div>
</body>

</html>