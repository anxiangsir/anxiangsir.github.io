<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Xiang An - Personal Homepage</title>
  <meta name="description" content="Xiang An - Research Scientist and Team Lead at GlintLab">
  <link rel="shortcut icon" href="assets/img/profile_pic.jpg">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
      font-size: 14px;
      line-height: 1.6;
      color: #202122;
      background: #f8f9fa;
    }

    /* Header */
    .wiki-header {
      background: #fff;
      border-bottom: 1px solid #a2a9b1;
      padding: 0.5em 0;
    }
    .wiki-header-inner {
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 1em;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }
    .wiki-logo {
      font-size: 1.1em;
      font-weight: bold;
      color: #202122;
      text-decoration: none;
    }
    .wiki-nav a {
      color: #0645ad;
      text-decoration: none;
      margin-left: 1.5em;
      font-size: 0.9em;
    }
    .wiki-nav a:hover { text-decoration: underline; }

    /* Main layout */
    .wiki-wrapper {
      max-width: 1400px;
      margin: 0 auto;
      display: flex;
      min-height: calc(100vh - 100px);
    }

    /* Left sidebar - TOC */
    .wiki-sidebar {
      width: 176px;
      flex-shrink: 0;
      background: #f8f9fa;
      border-right: 1px solid #a2a9b1;
      padding: 0.75em;
    }
    .wiki-sidebar-title {
      font-weight: bold;
      padding-bottom: 0.5em;
      border-bottom: 1px solid #c8ccd1;
      margin-bottom: 0.5em;
    }
    .wiki-sidebar ul {
      list-style: none;
      margin: 0;
      padding: 0;
    }
    .wiki-sidebar li {
      margin: 0.3em 0;
    }
    .wiki-sidebar a {
      color: #0645ad;
      text-decoration: none;
      font-size: 0.9em;
    }
    .wiki-sidebar a:hover { text-decoration: underline; }

    /* Content area */
    .wiki-content {
      flex: 1;
      background: #fff;
      border-left: 1px solid #a2a9b1;
      border-right: 1px solid #a2a9b1;
      padding: 1.5em 2em;
      min-width: 0;
    }

    /* Page title */
    .wiki-title {
      font-family: 'Linux Libertine', 'Georgia', 'Times', serif;
      font-size: 1.8em;
      font-weight: normal;
      border-bottom: 1px solid #a2a9b1;
      padding-bottom: 0.2em;
      margin-bottom: 0.5em;
    }

    /* Typography */
    h1, h2, h3, h4, h5, h6 {
      font-weight: normal;
      color: #000;
      margin-top: 1em;
      margin-bottom: 0.25em;
    }
    h2 {
      font-size: 1.5em;
      border-bottom: 1px solid #a2a9b1;
      padding-bottom: 0.2em;
    }
    h3 { font-size: 1.2em; }
    h4 { font-size: 1.1em; font-weight: bold; }
    h5 { font-size: 1em; font-weight: bold; }

    p { margin: 0.5em 0; }

    a { color: #0645ad; text-decoration: none; }
    a:hover { text-decoration: underline; }
    a:visited { color: #0b0080; }

    ul, ol { margin: 0.3em 0 0.3em 1.6em; }
    li { margin: 0.2em 0; }

    hr {
      border: none;
      border-top: 1px solid #a2a9b1;
      margin: 1em 0;
    }

    blockquote {
      border-left: 3px solid #c8ccd1;
      padding-left: 1em;
      margin: 1em 0;
      color: #54595d;
    }

    code {
      font-family: monospace;
      background: #f8f9fa;
      padding: 1px 4px;
      border: 1px solid #eaecf0;
    }
    pre {
      background: #f8f9fa;
      border: 1px solid #eaecf0;
      padding: 1em;
      overflow-x: auto;
      font-family: monospace;
      font-size: 0.9em;
    }

    /* Right sidebar - Infobox */
    .wiki-infobox-container {
      width: 260px;
      flex-shrink: 0;
      padding: 0.75em;
      background: #f8f9fa;
    }
    .infobox {
      border: 1px solid #a2a9b1;
      background: #f8f9fa;
      font-size: 0.9em;
      padding: 0.5em;
      position: sticky;
      top: 1em;
    }
    .infobox-title {
      background: #eaecf0;
      text-align: center;
      font-weight: bold;
      padding: 0.4em;
      margin: -0.5em -0.5em 0.5em -0.5em;
    }
    .infobox img {
      width: 100%;
      border: 1px solid #c8ccd1;
    }
    .infobox-caption {
      text-align: center;
      font-size: 0.85em;
      color: #54595d;
      padding: 0.3em 0;
    }
    .infobox-row {
      padding: 0.3em 0;
      border-top: 1px solid #eaecf0;
    }
    .infobox-label {
      font-weight: bold;
    }

    .infobox-row a {
      word-break: break-all;
    }
    .infobox-row i {
      width: 1.2em;
      text-align: center;
    }

    /* Publications */
    .publications { margin-top: 0.5em; }
    .publications ol.bibliography {
      list-style: none;
      padding: 0;
      margin: 0;
    }
    .publications ol.bibliography li {
      margin-bottom: 0.8em !important;
      padding-bottom: 0.6em !important;
      padding-top: 0.6em !important;
      margin-top: 0 !important;
      border-bottom: 1px solid #eaecf0;
    }
    .publications ol.bibliography li:last-child {
      border-bottom: none;
    }
    .publications ol.bibliography li .pub-entry .hidden {
      display: none;
    }
    .pub-entry {
      line-height: 1.4;
    }
    .pub-entry .periodical,
    .pub-entry .additional,
    .pub-entry .author {
      margin: 0.2em 0 0;
      line-height: 1.3;
    }
    .pub-entry .pub-number {
      display: none;
    }
    .pub-entry .title {
      font-weight: bold;
    }
    .pub-entry .title a {
      color: #0645ad;
    }
    .pub-entry .periodical {
      display: block;
      color: #54595d;
      font-size: 0.9em;
    }
    .pub-entry .periodical .genre-tag {
      display: inline-block;
      padding: 0.12em 0.45em;
      border: 1px solid #c8ccd1;
      border-radius: 3px;
      background: #f8f9fa;
      color: #54595d;
      font-size: 0.85em;
      font-style: normal;
      line-height: 1.2;
      margin: 0.15em 0.4em 0 0;
      max-width: 100%;
      white-space: normal;
      word-break: break-word;
    }
    .pub-entry .periodical .genre-tag-secondary {
      border-color: #eaecf0;
      background: #fff;
    }
    .pub-entry .periodical .genre-tag a {
      color: inherit;
      text-decoration: none;
    }
    .pub-entry .periodical .genre-tag a:hover {
      text-decoration: underline;
    }
    .pub-entry .additional {
      display: block;
      color: #5c4a1a;
      background: #fff8e1;
      border-left: 3px solid #d4a017;
      padding: 0.25em 0.5em;
      border-radius: 2px;
      font-weight: normal;
    }
    .pub-entry .author {
      display: block;
      color: #54595d;
      font-size: 0.9em;
    }
    .pub-entry .links {
      font-size: 0.85em;
      margin-left: 0.5em;
    }
    .pub-entry .links a {
      margin-right: 0.3em;
    }
    .pub-entry .hidden {
      max-height: 0;
      overflow: hidden;
      transition: max-height 0.2s ease;
      background: #f8f9fa;
      border: 1px solid #eaecf0;
      margin-top: 0.5em;
      font-size: 0.9em;
    }
    .pub-entry .hidden.open {
      max-height: 30em;
      padding: 0.5em;
    }

    /* Chat Box */
    .chat-section {
      background: transparent;
      border: none;
      padding: 0;
      margin-bottom: 2em;
    }
    .chat-container {
      background: #fff;
      border: 1px solid #e0e0e0;
      border-radius: 8px;
      padding: 1.25em;
      max-width: 750px;
      margin: 0 auto;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
    }
    .chat-header {
      font-weight: 600;
      font-size: 1.05em;
      margin-bottom: 0.75em;
      color: #202122;
      padding-bottom: 0.75em;
      border-bottom: 1px solid #e8e8e8;
    }
    .chat-messages {
      height: 250px;
      overflow-y: auto;
      padding: 0.75em;
      margin-bottom: 0.75em;
      background: #fafafa;
      border: 1px solid #e8e8e8;
      border-radius: 6px;
    }
    .chat-messages::-webkit-scrollbar {
      width: 6px;
    }
    .chat-messages::-webkit-scrollbar-track {
      background: #f1f1f1;
      border-radius: 3px;
    }
    .chat-messages::-webkit-scrollbar-thumb {
      background: #c1c1c1;
      border-radius: 3px;
    }
    .chat-messages::-webkit-scrollbar-thumb:hover {
      background: #a8a8a8;
    }
    .chat-message {
      margin: 0.6em 0;
      padding: 0.6em 0.9em;
      border-radius: 6px;
      line-height: 1.5;
      animation: fadeIn 0.25s ease-out;
      max-width: 85%;
    }
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(8px); }
      to { opacity: 1; transform: translateY(0); }
    }
    .chat-message.user {
      background: #e3f2fd;
      border-left: 3px solid #2196f3;
      margin-left: auto;
      margin-right: 0;
    }
    .chat-message.assistant {
      background: #fff;
      border: 1px solid #e0e0e0;
      border-left: 3px solid #4caf50;
      margin-left: 0;
      margin-right: auto;
    }
    .chat-message-label {
      font-weight: 600;
      font-size: 0.8em;
      color: #666;
      margin-bottom: 0.25em;
      text-transform: uppercase;
      letter-spacing: 0.3px;
    }
    .chat-input-container {
      display: flex;
      gap: 0.5em;
      align-items: stretch;
    }
    .chat-input {
      flex: 1;
      padding: 0.7em 0.9em;
      border: 1px solid #d0d0d0;
      border-radius: 6px;
      font-family: inherit;
      font-size: 0.95em;
      transition: all 0.2s ease;
    }
    .chat-input:focus {
      outline: none;
      border-color: #2196f3;
      box-shadow: 0 0 0 3px rgba(33, 150, 243, 0.1);
    }
    .chat-send-btn {
      padding: 0.7em 1.8em;
      background: linear-gradient(135deg, #2196f3 0%, #1976d2 100%);
      color: #fff;
      border: none;
      border-radius: 6px;
      font-family: inherit;
      font-size: 0.95em;
      cursor: pointer;
      font-weight: 600;
      transition: all 0.2s ease;
      box-shadow: 0 2px 4px rgba(33, 150, 243, 0.2);
    }
    .chat-send-btn:hover {
      background: linear-gradient(135deg, #1976d2 0%, #1565c0 100%);
      box-shadow: 0 3px 6px rgba(33, 150, 243, 0.3);
      transform: translateY(-1px);
    }
    .chat-send-btn:active {
      transform: translateY(0);
      box-shadow: 0 1px 2px rgba(33, 150, 243, 0.2);
    }
    .chat-send-btn:disabled {
      background: #bdbdbd;
      cursor: not-allowed;
      box-shadow: none;
      transform: none;
    }

    /* Footer */
    .wiki-footer {
      text-align: center;
      padding: 1em;
      font-size: 0.85em;
      color: #54595d;
      border-top: 1px solid #a2a9b1;
      background: #f8f9fa;
    }

    /* Hide TOC in content when sidebar exists */
    .toc { display: none; }

    /* Responsive */
    @media (max-width: 900px) {
      .wiki-wrapper {
        flex-direction: column;
      }
      .wiki-sidebar {
        width: 100%;
        border-right: none;
        border-bottom: 1px solid #a2a9b1;
      }
      .wiki-infobox-container {
        width: 100%;
        order: -1;
      }
      .infobox {
        max-width: 400px;
        margin: 0 auto;
      }
      .infobox img {
        max-width: 250px;
        width: 100%;
        margin: 0 auto;
        display: block;
      }
      .wiki-content {
        border-left: none;
        border-right: none;
        padding: 1em;
      }
      
      /* Mobile chat optimizations */
      .chat-container {
        padding: 1em;
        border-radius: 6px;
      }
      .chat-header {
        font-size: 1em;
        padding-bottom: 0.6em;
        margin-bottom: 0.6em;
      }
      .chat-messages {
        height: 200px;
        padding: 0.6em;
        margin-bottom: 0.6em;
      }
      .chat-message {
        margin: 0.5em 0;
        padding: 0.5em 0.7em;
        font-size: 0.95em;
        max-width: 90%;
      }
      .chat-message-label {
        font-size: 0.75em;
      }
      .chat-input-container {
        flex-direction: row;
        gap: 0.4em;
      }
      .chat-input {
        padding: 0.65em 0.75em;
        font-size: 0.9em;
        min-width: 0;
      }
      .chat-send-btn {
        padding: 0.65em 1.2em;
        font-size: 0.9em;
        white-space: nowrap;
      }
    }
    
    @media (max-width: 600px) {
      .chat-messages {
        height: 180px;
      }
      .chat-message {
        max-width: 95%;
      }
      .chat-input {
        font-size: 16px; /* Prevent zoom on iOS */
      }
      .chat-send-btn {
        padding: 0.65em 1em;
      }
    }
  </style>
</head>
<body>
  <header class="wiki-header">
    <div class="wiki-header-inner">
      <a href="/" class="wiki-logo">Personal Homepage</a>
      <nav class="wiki-nav">
      </nav>
    </div>
  </header>

  <div class="wiki-wrapper">
    <aside class="wiki-sidebar">
      <div class="wiki-sidebar-title">Contents</div>
      <ul>
        <li><a href="#">(Top)</a></li>
        <li><a href="#chat">Ask Xiang An anything</a></li>
        <li><a href="#publications">Publications</a></li>
        <li><a href="#awards">Awards</a></li>
        <li><a href="#open-source">Open Source</a></li>
        <li><a href="#external-links">External Links</a></li>
      </ul>
    </aside>

    <main class="wiki-content">
      <h1 class="wiki-title">Xiang An</h1>

<p><b>Xiang An</b> (Chinese: ÂÆâÁøî) is a <b>Research Scientist</b> and <b>Team Lead</b> of the Multimodal Large Model Group at <b>GlintLab</b>, specializing in computer vision and multimodal large models. His current research focuses on building the <b>next-generation Vision Transformer (ViT)</b> to address urgent needs in modern <abbr title="Multimodal Large Language Models">MLLMs</abbr>. He is also the <b>#2 contributor</b> to the <a href="https://github.com/deepinsight/insightface" target="_blank">InsightFace</a> ecosystem (~27k‚≠ê). His research has accumulated <b>1,114+ citations</b> on <a href="https://scholar.google.com.hk/citations?user=1ckaPgwAAAAJ&hl=en" target="_blank">Google Scholar</a>, and his open-source projects have garnered a total of <b>34,177+ stars</b> on GitHub.</p>

<h2 id="chat">Ask Xiang An anything</h2>

<div class="chat-section">
  <div class="chat-container">
    <div class="chat-header">üí¨ Chat</div>
    <div class="chat-messages" id="chatMessages">
      <div class="chat-message assistant">
        <div class="chat-message-label">Âä©Êâã</div>
        <div>‰Ω†Â•ΩÔºÅÊ¨¢ËøéÊù•Âà∞ÂÆâÁøîÁöÑ‰∏ªÈ°µ„ÄÇÊàëÁõÆÂâçÊ≠£Âú®ÂçáÁ∫ß‰∏≠,Êï¨ËØ∑ÊúüÂæÖÔºÅ</div>
      </div>
    </div>
    <div class="chat-input-container">
      <input type="text" id="chatInput" class="chat-input" placeholder="ËæìÂÖ•ÊÇ®ÁöÑÊ∂àÊÅØ..." />
      <button id="chatSendBtn" class="chat-send-btn">ÂèëÈÄÅ</button>
    </div>
  </div>
</div>

<h2 id="publications">Publications</h2>

<p>The following is a selection of notable publications. For a complete list, see <a href="publications.html">All Publications</a>.</p>

<div class="publications">
<ol class="bibliography">
<li><div class="pub-entry">
    <span class="title"><a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5">LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training</a></span>
    <span class="periodical"><span class="genre-tag">Preprint 2025</span>
      <span class="genre-tag genre-tag-secondary"><a href="https://arxiv.org/abs/2509.23661" target="_blank">Paper</a></span>
      <span class="genre-tag genre-tag-secondary"><a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" target="_blank">Code</a></span>
    </span>
    <span class="additional">Fully open-source code, data, checkpoints and training logs; Provided a better open-source ViT; Proved the idea that simple scaling dense captions would improve overall multimodal tasks performance</span>
    <span class="author"><b><u>Xiang An</u></b>, Yin Xie, Kaicheng Yang, Wenkang Zhang, Xiuwei Zhao, Zheng Cheng, Changrui Chen, Zizhen Yan, Ziyong Feng, Ziwei Liu, Bo Li, Jiankang Deng, et al.</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://arxiv.org/abs/2510.13515">UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning</a></span>
    <span class="periodical"><span class="genre-tag">AAAI 2026 (Oral)</span>
      <span class="genre-tag genre-tag-secondary"><a href="https://github.com/GaryGuTC/UniME-v2" target="_blank">Code</a></span>
    </span>
    <span class="author">Tiancheng Gu, Kaicheng Yang, Kaichen Zhang, <b><u>Xiang An</u></b>, Ziyong Feng, Yueyi Zhang, Weidong Cai, Jiankang Deng, Lidong Bing</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://arxiv.org/abs/2507.20025">Region-based Cluster Discrimination for Visual Representation Learning</a></span>
    <span class="periodical"><span class="genre-tag">ICCV 2025 (Highlight)</span>
      <span class="genre-tag genre-tag-secondary"><a href="https://github.com/deepglint/unicom" target="_blank">Code</a></span>
    </span>
    <span class="additional">Novel approach to self-supervised learning by introducing region-based cluster discrimination.</span>
    <span class="author">Yin Xie, Kaicheng Yang, <b><u>Xiang An (Project Leader)</u></b>, Kun Wu, Yongle Zhao, Weimo Deng, Zimin Ran, Yumeng Wang, Ziyong Feng, Jiankang Deng</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://arxiv.org/abs/2407.17331">Multi-label Cluster Discrimination for Visual Representation Learning</a></span>
    <span class="periodical"><span class="genre-tag">ECCV 2024</span>
      <span class="genre-tag genre-tag-secondary"><a href="https://github.com/deepglint/unicom" target="_blank">Code</a></span>
    </span>
    <span class="additional">Multi-label cluster discrimination framework for self-supervised visual representation learning</span>
    <span class="author"><b><u>Xiang An</u></b>, Kaicheng Yang, Xiangzi Dai, Ziyong Feng, Jiankang Deng</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://arxiv.org/abs/2304.05884">Unicom: Universal and Compact Representation Learning for Image Retrieval</a></span>
    <span class="periodical"><span class="genre-tag">ICLR 2023</span>
      <span class="genre-tag genre-tag-secondary"><a href="https://github.com/deepglint/unicom" target="_blank">Code</a></span>
    </span>
    <span class="additional">Universal and compact representation learning framework for large-scale image retrieval. Foundation for scalable image retrieval systems</span>
    <span class="author"><b><u>Xiang An</u></b>, Jiankang Deng, Kaicheng Yang, Jiawei Li, Ziyong Feng, Jia Guo, Jing Yang, Tongliang Liu</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://arxiv.org/abs/2203.15565">Killing Two Birds with One Stone: Efficient and Robust Training of Face Recognition CNNs by Partial FC</a></span>
    <span class="periodical"><span class="genre-tag">CVPR 2022</span>
      <span class="genre-tag genre-tag-secondary"><a href="https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch" target="_blank">Code</a></span>
    </span>
    <span class="additional">Enabling training of 10 million identities on a single machine through innovative Partial FC approach</span>
    <span class="author"><b><u>Xiang An</u></b>, Jiankang Deng, Jia Guo, Ziyong Feng, Xuhan Zhu, Jing Yang, Tongliang Liu</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://arxiv.org/abs/2010.05222">Partial FC: Training 10 Million Identities on a Single Machine</a></span>
    <span class="periodical"><span class="genre-tag">ICCVW 2021</span>
      <span class="genre-tag genre-tag-secondary"><a href="https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch" target="_blank">Code</a></span>
    </span>
    <span class="author"><b><u>Xiang An</u></b>, Xuhan Zhu, Yuan Gao, Yang Xiao, Yongle Zhao, Ziyong Feng, Lan Wu, Bin Qin, Ming Zhang, Debing Zhang, Ying Fu</span>
</div>
</li>
</ol>
</div>

<h2 id="awards">Awards & Competitions</h2>

<ul>
  <li><b>ICCV 2025 Outstanding Reviewer</b></li>
  <li><b>CVPR 2024 Outstanding Reviewer</b></li>
  <li><b>Ranked 1st in NIST FRVT Competition, Visa Track 1:1</b></li>
  <li><b>2024 ‰∏≠ÂõΩÂπ¥Â∫¶ÂäõÈáè‰∫∫Áâ©ÊèêÂêç</b></li>
  <li><b>Ranked 1st in the graduate entrance examination (major)</b></li>
  <li><b>First Place in Vehicle Re-Identification, PRCV 2019</b></li>
</ul>

<h2 id="open-source">Open Source</h2>

<div class="publications">
<ol class="bibliography">
<li><div class="pub-entry">
    <span class="title"><a href="https://github.com/deepinsight/insightface" target="_blank">InsightFace</a> <span class="stars-insightface"></span></span>
    <span class="periodical"><span class="genre-tag">Open Source Library</span></span>
    <span class="author">#2 contributor to the open-source 2D & 3D deep face analysis library. Author of Glint360K (the largest open-source face recognition training dataset) and Partial FC (enabling training 10 million identities on a single machine). Also organized the ICCV 2021 Workshop on masked face recognition challenge.</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" target="_blank">LLaVA-OneVision-1.5</a> <span class="stars-llava-onevision"></span></span>
    <span class="periodical"><span class="genre-tag">Multimodal LLM Framework</span></span>
    <span class="author">Team Leader of this fully open framework designed to democratize multimodal training. Released mid-training and instruct data for community use, and developed offline sampling pack for efficient training. Implemented RiceViT with native resolution support.</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://github.com/deepglint/unicom" target="_blank">UNICOM</a> <span class="stars-unicom"></span></span>
    <span class="periodical"><span class="genre-tag">Image Retrieval Framework</span></span>
    <span class="author">Lead author and maintainer of Universal and Compact Representation Learning framework for universal image representations. Designed the novel cluster discrimination approach for representation learning. Developed the multi-label and region-based extensions (published at ECCV 2024 and ICCV 2025 (Highlight)).</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://github.com/LLaVA-VL/LLaVA-NeXT" target="_blank">LLaVA-NeXT</a> <span class="stars-llava-next"></span></span>
    <span class="periodical"><span class="genre-tag">Large Multimodal Model</span></span>
    <span class="author">Vision module contributor to the next-generation large multimodal model. Enhanced the OCR capability of the vision module for better text recognition in images. Optimized the visual encoder for processing text-rich and document images.</span>
</div>
</li>

<li><div class="pub-entry">
    <span class="title"><a href="https://github.com/anxiangsir/urban_seg" target="_blank">Urban Seg</a> <span class="stars-urban-seg"></span></span>
    <span class="periodical"><span class="genre-tag">Educational Project</span></span>
    <span class="author">Author and maintainer of this educational project for semantic segmentation on remote sensing and satellite imagery. Designed a simple single-file training approach for accessibility and integrated popular pretrained models. Created comprehensive tutorials and documentation for beginners.</span>
</div>
</li>
</ol>
</div>

<h2 id="external-links">External Links</h2>

<ul>
  <li><a href="mailto:anxiangsir@outlook.com"><i class="fas fa-envelope"></i> Email: anxiangsir@outlook.com</a></li>
  <li><a href="https://scholar.google.com.hk/citations?user=1ckaPgwAAAAJ&hl=en" target="_blank"><i class="ai ai-google-scholar"></i> Google Scholar Profile</a></li>
  <li><a href="https://github.com/anxiangsir" target="_blank"><i class="fab fa-github"></i> GitHub: anxiangsir</a></li>
  <li><a href="https://github.com/deepinsight/insightface" target="_blank"><i class="fab fa-github"></i> InsightFace Project</a></li>
</ul>

<hr />

<p><em>This page is styled after <a href="https://en.wikipedia.org/">Wikipedia</a>.</em></p>

    </main>

    <aside class="wiki-infobox-container">
      <div class="infobox">
        <div class="infobox-title">Xiang An</div>

        <img src="assets/img/profile_pic.jpg" alt="Xiang An">
        <div class="infobox-row">
          <span class="infobox-label">Position</span><br>
          Research Scientist, Team Lead
        </div>
        <div class="infobox-row">
          <span class="infobox-label">Field</span><br>
          Computer Vision, Multimodal AI
        </div>
        <div class="infobox-row">
          <span class="infobox-label">Notable Work</span><br>
          InsightFace, UNICOM/MLCD, LLaVA-OneVision-1.5, OneVision-Encoder
        </div>

        <div class="infobox-row">
          <span class="infobox-label">GitHub</span><br>
          <a href="https://github.com/anxiangsir"><i class="fab fa-github"></i> anxiangsir</a>
        </div>

        <div class="infobox-row">
          <span class="infobox-label">Google Scholar</span><br>
          <a href="https://scholar.google.com.hk/citations?user=1ckaPgwAAAAJ&hl=en"><i class="ai ai-google-scholar"></i> Profile</a>
        </div>

        <div class="infobox-row">
          <span class="infobox-label">Citations</span><br>
          1,114+ (Google Scholar)
        </div>

        <div class="infobox-row">
          <span class="infobox-label">GitHub Stars</span><br>
          34,177+ total
        </div>

        <div class="infobox-row">
          <span class="infobox-label">Email</span><br>
          <a href="mailto:anxiangsir@outlook.com"><i class="fas fa-envelope"></i> Contact</a>
        </div>
      </div>
    </aside>
  </div>

  <footer class="wiki-footer">
    This page was last edited on January 28, 2025.
  </footer>

  <!-- GitHub Stars Loader -->
  <script src="assets/js/github-stars.js"></script>
  
  <!-- Chat functionality -->
  <script>
    (function() {
      // Constants
      const UPGRADE_MESSAGE = 'ÂçáÁ∫ß‰∏≠ÔºÅ';
      const SIMULATED_RESPONSE_DELAY_MS = 500;
      
      const chatMessages = document.getElementById('chatMessages');
      const chatInput = document.getElementById('chatInput');
      const chatSendBtn = document.getElementById('chatSendBtn');

      function addMessage(text, isUser) {
        const messageDiv = document.createElement('div');
        messageDiv.className = `chat-message ${isUser ? 'user' : 'assistant'}`;
        
        const labelDiv = document.createElement('div');
        labelDiv.className = 'chat-message-label';
        labelDiv.textContent = isUser ? 'Áî®Êà∑' : 'Âä©Êâã';
        
        const contentDiv = document.createElement('div');
        contentDiv.textContent = text;
        
        messageDiv.appendChild(labelDiv);
        messageDiv.appendChild(contentDiv);
        chatMessages.appendChild(messageDiv);
        
        // Scroll to bottom
        chatMessages.scrollTop = chatMessages.scrollHeight;
      }

      function sendMessage() {
        const message = chatInput.value.trim();
        if (!message) return;
        
        // Add user message
        addMessage(message, true);
        chatInput.value = '';
        
        // Disable button temporarily
        chatSendBtn.disabled = true;
        
        // Simulate thinking delay
        setTimeout(() => {
          // TODO: Replace with actual OpenAI API call
          // For now, always respond with UPGRADE_MESSAGE
          addMessage(UPGRADE_MESSAGE, false);
          chatSendBtn.disabled = false;
          chatInput.focus();
        }, SIMULATED_RESPONSE_DELAY_MS);
      }

      // Event listeners
      chatSendBtn.addEventListener('click', sendMessage);
      chatInput.addEventListener('keypress', (e) => {
        if (e.key === 'Enter') {
          sendMessage();
        }
      });

      // TODO: Future OpenAI API integration
      // async function callOpenAI(message) {
      //   try {
      //     const response = await fetch('/api/chat', {
      //       method: 'POST',
      //       headers: {
      //         'Content-Type': 'application/json',
      //       },
      //       body: JSON.stringify({ message: message })
      //     });
      //     const data = await response.json();
      //     return data.reply;
      //   } catch (error) {
      //     console.error('Error calling OpenAI API:', error);
      //     return 'Êä±Ê≠âÔºåÊúçÂä°ÊöÇÊó∂‰∏çÂèØÁî®„ÄÇ';
      //   }
      // }
    })();
  </script>
</body>
</html>
